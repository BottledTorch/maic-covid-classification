{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b5696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import imagesize\n",
    "import concurrent.futures\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "import skimage, torch, torchvision\n",
    "import numpy as np\n",
    "import skimage\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b41681",
   "metadata": {},
   "source": [
    "## Setting up DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfe6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.txt', header=None)\n",
    "train_df = pd.read_csv('train.txt', header=None)\n",
    "validation_df = pd.read_csv('val.txt', header=None)\n",
    "\n",
    "all_df = [test_df, train_df, validation_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a18a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda function\n",
    "split_function = lambda df: df[0].str.split(' ', expand=True)\n",
    "\n",
    "# Apply the lambda function to each DataFrame in the list\n",
    "all_df = list(map(split_function, all_df))\n",
    "\n",
    "# Define the lambda function\n",
    "rename_function = lambda df: df.rename(columns={0: \"test_id\", 1: 'filename', 2: 'test_result', 3: 'data_source'}, inplace=False)\n",
    "\n",
    "# Apply the lambda function to each DataFrame in the list and create a new list\n",
    "all_df = [rename_function(df) for df in all_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d63ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda function\n",
    "create_filepath = lambda df, dir_name: df.assign(full_filepath=df.apply(lambda row: os.path.join(dir_name, row.filename), axis=1))\n",
    "\n",
    "# Directory names corresponding to each DataFrame\n",
    "dir_names = ['test', 'train', 'val']\n",
    "\n",
    "# Apply the lambda function to each DataFrame along with the corresponding directory name\n",
    "all_df = [create_filepath(df, dir_name) for df, dir_name in zip(all_df, dir_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dce081",
   "metadata": {},
   "source": [
    "### Enriching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES A HOT MINUTE\n",
    "\n",
    "# Define the function to add dimensions to a single row\n",
    "def add_image_dimensions(row):\n",
    "    width, height = imagesize.get(row.full_filepath)\n",
    "    return pd.Series([width, height], index=['x_shape', 'y_shape'])\n",
    "\n",
    "# Function to process a single dataframe\n",
    "def process_dataframe(df):\n",
    "    dimensions = df.apply(add_image_dimensions, axis=1)\n",
    "    return pd.concat([df, dimensions], axis=1)\n",
    "\n",
    "# Process each dataframe in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    all_df = list(executor.map(process_dataframe, [all_df[0].head(10)]))\n",
    "\n",
    "# todo, go through all 3 dataframes\n",
    "max_x = all_df[0]['x_shape'].max()\n",
    "max_y = all_df[0]['y_shape'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_shape(a, y_, x_):\n",
    "    a = tf.squeeze(a)\n",
    "    y, x = a.shape\n",
    "    y_pad = (y_-y)\n",
    "    x_pad = (x_-x)\n",
    "    return np.pad(a,((y_pad//2, y_pad//2 + y_pad%2), \n",
    "                     (x_pad//2, x_pad//2 + x_pad%2)),\n",
    "                  mode = 'constant')\n",
    "\n",
    "# Initialize the model\n",
    "model = xrv.baseline_models.chestx_det.PSPNet()\n",
    "\n",
    "# Define the transformation\n",
    "transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(), xrv.datasets.XRayResizer(512)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec90cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to process an individual image\n",
    "def process_image(img_path):\n",
    "    # Read and process the image\n",
    "    img = skimage.io.imread(img_path)\n",
    "    img = xrv.datasets.normalize(img, 255)\n",
    "    if img.ndim == 2:\n",
    "        img = img[None, ...]\n",
    "    elif img.ndim == 3:\n",
    "        img = img.mean(2)[None, ...]\n",
    "\n",
    "    img = transform(img)\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    \n",
    "    # Get the model prediction\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor)\n",
    "\n",
    "    # Process the prediction\n",
    "    pred = 1 / (1 + np.exp(-pred))\n",
    "    pred[pred < 0.5] = 0\n",
    "    pred[pred >= 0.5] = 1\n",
    "    \n",
    "    lung_mask = pred[0, 0]  # Adjust this index based on how your model outputs the prediction\n",
    "\n",
    "    # Find the indices where lung_mask is 1\n",
    "    lung_indices = np.where(lung_mask == 1)\n",
    "    \n",
    "    right_lung_index = model.targets.index('Right Lung')\n",
    "    left_lung_index = model.targets.index('Left Lung')\n",
    "    \n",
    "    \n",
    "    # Pull out just the lung pixels that we care about, using a logical or\n",
    "    segmented_lungs_prediction = np.logical_or(pred[0,left_lung_index], pred[0,right_lung_index])\n",
    "    \n",
    "    # Map this back onto the original image\n",
    "    segmented_lungs = segmented_lungs_prediction*img\n",
    "        \n",
    "    padded_segmented_lungs = to_shape(segmented_lungs, max_y, max_x)\n",
    "\n",
    "    \n",
    "#     plt.imshow(padded_segmented_lungs, cmap='gray')\n",
    "#     plt.show()\n",
    "\n",
    "    jpg_im_path = img_path.replace('.png', '').replace('.jpg', '')\n",
    "    file_name = f'etl_output/{jpg_im_path}'\n",
    "    np.save(file_name, padded_segmented_lungs)\n",
    "    \n",
    "    return None\n",
    "\n",
    "#     # Calculate the extents\n",
    "#     top_extent = np.min(lung_indices[0]) if lung_indices[0].size > 0 else None\n",
    "#     bottom_extent = np.max(lung_indices[0]) if lung_indices[0].size > 0 else None\n",
    "#     left_extent = np.min(lung_indices[1]) if lung_indices[1].size > 0 else None\n",
    "#     right_extent = np.max(lung_indices[1]) if lung_indices[1].size > 0 else None\n",
    "    \n",
    "#     # Find the center x,y of the lungs\n",
    "#     center_x = right_extent-left_extent\n",
    "#     center_y = bottom_extent-top_extent\n",
    "\n",
    "#     return left_extent, right_extent, top_extent, bottom_extent\n",
    "\n",
    "# Define the function to process a single dataframe\n",
    "def process_dataframe(df):\n",
    "    # Apply the image processing to each row\n",
    "    extents = df['full_filepath'].apply(process_image)\n",
    "#     extents_df = pd.DataFrame(extents.tolist(), columns=['left_extent', 'right_extent', 'top_extent', 'bottom_extent'])\n",
    "\n",
    "#     return pd.concat([df, extents_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317a1c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Check to make sure this works\n",
    "# Process each dataframe\n",
    "start = time.time()\n",
    "# all_df_processed = [process_dataframe(df) for df in all_df]\n",
    "process_dataframe(all_df[0].head(10))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc04dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
